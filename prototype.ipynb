{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd04c2c6958f73f61d7b8bffd4193a0d9584c9ef39256921fe54ce430734ddbdc1d",
   "display_name": "Python 3.9.4 64-bit ('QandU': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      ID                                           Sentence  Votes       MOS  \\\n",
       "0    130  Weitergehende Sicherungsmaßnahmen können eine ...     10  3.800000   \n",
       "1    902  In der großen Kasernenanlage im Norden Kiels k...      7  2.285714   \n",
       "2    816  Premierminister David Lloyd George honorierte ...      8  3.000000   \n",
       "3    813  Der Beitrag der Truppen dieser Dominions währe...     10  4.000000   \n",
       "4    293  Eine Balance zwischen verschiedenen Lebensbere...     10  4.900000   \n",
       "..   ...                                                ...    ...       ...   \n",
       "895  384  Zwischen 1901 und 2010 ist er um ca 1,7 cm pro...      8  3.375000   \n",
       "896  869  Aus Furcht vor einem Bürgerkrieg wollte sie – ...     17  4.058824   \n",
       "897  932  In den meisten Politikfeldern gilt dafür seit ...      9  5.111111   \n",
       "898  546  Aufgrund der Wärmekapazität des Gesteins, und ...     10  5.000000   \n",
       "899  256  Die Klinge ist zumeist aus nicht rostfreiem Ko...     10  3.600000   \n",
       "\n",
       "          Std  \n",
       "0    1.316561  \n",
       "1    1.112697  \n",
       "2    0.755929  \n",
       "3    0.942809  \n",
       "4    1.449138  \n",
       "..        ...  \n",
       "895  0.916125  \n",
       "896  1.712841  \n",
       "897  0.781736  \n",
       "898  1.699673  \n",
       "899  0.516398  \n",
       "\n",
       "[900 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Sentence</th>\n      <th>Votes</th>\n      <th>MOS</th>\n      <th>Std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>130</td>\n      <td>Weitergehende Sicherungsmaßnahmen können eine ...</td>\n      <td>10</td>\n      <td>3.800000</td>\n      <td>1.316561</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>902</td>\n      <td>In der großen Kasernenanlage im Norden Kiels k...</td>\n      <td>7</td>\n      <td>2.285714</td>\n      <td>1.112697</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>816</td>\n      <td>Premierminister David Lloyd George honorierte ...</td>\n      <td>8</td>\n      <td>3.000000</td>\n      <td>0.755929</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>813</td>\n      <td>Der Beitrag der Truppen dieser Dominions währe...</td>\n      <td>10</td>\n      <td>4.000000</td>\n      <td>0.942809</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>293</td>\n      <td>Eine Balance zwischen verschiedenen Lebensbere...</td>\n      <td>10</td>\n      <td>4.900000</td>\n      <td>1.449138</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>384</td>\n      <td>Zwischen 1901 und 2010 ist er um ca 1,7 cm pro...</td>\n      <td>8</td>\n      <td>3.375000</td>\n      <td>0.916125</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>869</td>\n      <td>Aus Furcht vor einem Bürgerkrieg wollte sie – ...</td>\n      <td>17</td>\n      <td>4.058824</td>\n      <td>1.712841</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>932</td>\n      <td>In den meisten Politikfeldern gilt dafür seit ...</td>\n      <td>9</td>\n      <td>5.111111</td>\n      <td>0.781736</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>546</td>\n      <td>Aufgrund der Wärmekapazität des Gesteins, und ...</td>\n      <td>10</td>\n      <td>5.000000</td>\n      <td>1.699673</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>256</td>\n      <td>Die Klinge ist zumeist aus nicht rostfreiem Ko...</td>\n      <td>10</td>\n      <td>3.600000</td>\n      <td>0.516398</td>\n    </tr>\n  </tbody>\n</table>\n<p>900 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "#own functions\n",
    "\n",
    "data_set = pd.read_excel(\"Dataset/\"+\"training.xlsx\")\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     dativ  akkusativ  genitiv  num_words  longest_word_length  \\\n",
       "0        1          0        0         31                   22   \n",
       "1        1          0        0         11                   22   \n",
       "2        1          1        0         28                   22   \n",
       "3        1          0        0         24                   22   \n",
       "4        1          0        0         36                   22   \n",
       "..     ...        ...      ...        ...                  ...   \n",
       "894      1          0        1         23                   18   \n",
       "895      1          0        0         27                   18   \n",
       "896      1          1        0         29                   18   \n",
       "897      1          1        0         43                   18   \n",
       "898      1          0        1         32                   18   \n",
       "\n",
       "     shortest_word_length    target  \n",
       "0                       2  3.800000  \n",
       "1                       2  2.285714  \n",
       "2                       2  3.000000  \n",
       "3                       2  4.000000  \n",
       "4                       2  4.900000  \n",
       "..                    ...       ...  \n",
       "894                     2  3.777778  \n",
       "895                     2  3.375000  \n",
       "896                     2  4.058824  \n",
       "897                     2  5.111111  \n",
       "898                     2  5.000000  \n",
       "\n",
       "[899 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dativ</th>\n      <th>akkusativ</th>\n      <th>genitiv</th>\n      <th>num_words</th>\n      <th>longest_word_length</th>\n      <th>shortest_word_length</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>22</td>\n      <td>2</td>\n      <td>3.800000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>22</td>\n      <td>2</td>\n      <td>2.285714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>28</td>\n      <td>22</td>\n      <td>2</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>22</td>\n      <td>2</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36</td>\n      <td>22</td>\n      <td>2</td>\n      <td>4.900000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>23</td>\n      <td>18</td>\n      <td>2</td>\n      <td>3.777778</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27</td>\n      <td>18</td>\n      <td>2</td>\n      <td>3.375000</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>29</td>\n      <td>18</td>\n      <td>2</td>\n      <td>4.058824</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>43</td>\n      <td>18</td>\n      <td>2</td>\n      <td>5.111111</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>32</td>\n      <td>18</td>\n      <td>2</td>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>899 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "target = []\n",
    "splited_words = []\n",
    "num_words = []\n",
    "num_letters_array = []\n",
    "longest_word_length = []\n",
    "shortest_word_length = []\n",
    "genitiv = []\n",
    "akkusativ = []\n",
    "dativ =[]\n",
    "\n",
    "for x in range(max(data_set.index)):\n",
    "    current_target = data_set.loc[x,'MOS']\n",
    "    target.append(current_target)\n",
    "    current_sentence = data_set.loc[x,'Sentence']\n",
    "    splited_words.append(current_sentence.split())\n",
    "    num_words.append(len(splited_words[x]))\n",
    "    num_letters = []\n",
    "        \n",
    "    if \"des\" in current_sentence:\n",
    "        genitiv.append(1)\n",
    "    else:\n",
    "        genitiv.append(0)\n",
    "\n",
    "    if \"dem\" in current_sentence:\n",
    "        akkusativ.append(1)\n",
    "    else:\n",
    "        akkusativ.append(0)\n",
    "\n",
    "    if \"den\" in current_sentence:\n",
    "        dativ.append(1)\n",
    "    else:\n",
    "        dativ.append(1)\n",
    "\n",
    "    for y in range (num_words[x]):\n",
    "        current_word = splited_words[x][y]\n",
    "\n",
    "        num_letters.append(len(current_word))\n",
    "        num_letters_array.append(num_letters)\n",
    "\n",
    "    longest_word_length.append(max(num_letters_array[x])) \n",
    "    shortest_word_length.append(min(num_letters_array[x])) \n",
    "\n",
    "feature_dict = {\n",
    "    'dativ':dativ, \n",
    "    'akkusativ': akkusativ, \n",
    "    'genitiv': genitiv, \n",
    "    'num_words':num_words, \n",
    "    'longest_word_length':longest_word_length,\n",
    "    'shortest_word_length':shortest_word_length, \n",
    "    'target':target\n",
    "    }\n",
    "feature_dataframe = pd.DataFrame(data=feature_dict)\n",
    "feature_dataframe   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     dativ  genitiv\n",
       "372      1        0\n",
       "104      1        1\n",
       "730      1        0\n",
       "325      1        0\n",
       "395      1        0\n",
       "..     ...      ...\n",
       "533      1        0\n",
       "170      1        0\n",
       "224      1        0\n",
       "800      1        0\n",
       "810      1        0\n",
       "\n",
       "[180 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dativ</th>\n      <th>genitiv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>372</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>730</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>325</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>533</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>800</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>180 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = feature_dataframe.drop(['target'], axis=1)\n",
    "y = feature_dataframe['target']\n",
    "\n",
    "X_test, X_train,  y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train[['dativ','genitiv']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-6-972b59225ed9>:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[['num_words', 'longest_word_length', 'shortest_word_length']] = scaler.fit_transform(X_train[['num_words', 'longest_word_length', 'shortest_word_length']])\nC:\\Anaconda3\\envs\\QandU\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n<ipython-input-6-972b59225ed9>:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test[['num_words', 'longest_word_length', 'shortest_word_length']] = scaler.transform(X_test[['num_words', 'longest_word_length', 'shortest_word_length']])\nC:\\Anaconda3\\envs\\QandU\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     dativ  akkusativ  genitiv  num_words  longest_word_length  \\\n",
       "328      1          1        1  -0.176600            -1.203874   \n",
       "714      1          0        1   2.472407            -1.000402   \n",
       "260      1          0        0  -0.706402             2.458616   \n",
       "812      1          0        0  -1.412804             0.016956   \n",
       "18       1          0        0  -0.706402             1.034314   \n",
       "..     ...        ...      ...        ...                  ...   \n",
       "120      1          0        0   2.737308             1.237786   \n",
       "773      1          1        1   0.883002             0.220428   \n",
       "99       1          0        0  -1.059603             1.237786   \n",
       "722      1          0        0  -1.324504            -1.000402   \n",
       "720      1          0        0  -0.618102            -1.000402   \n",
       "\n",
       "     shortest_word_length  \n",
       "328              1.603675  \n",
       "714             -0.167254  \n",
       "260             -0.167254  \n",
       "812             -1.938184  \n",
       "18              -0.167254  \n",
       "..                    ...  \n",
       "120             -0.167254  \n",
       "773              1.603675  \n",
       "99              -0.167254  \n",
       "722             -1.938184  \n",
       "720             -1.938184  \n",
       "\n",
       "[719 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dativ</th>\n      <th>akkusativ</th>\n      <th>genitiv</th>\n      <th>num_words</th>\n      <th>longest_word_length</th>\n      <th>shortest_word_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>328</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.176600</td>\n      <td>-1.203874</td>\n      <td>1.603675</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.472407</td>\n      <td>-1.000402</td>\n      <td>-0.167254</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.706402</td>\n      <td>2.458616</td>\n      <td>-0.167254</td>\n    </tr>\n    <tr>\n      <th>812</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.412804</td>\n      <td>0.016956</td>\n      <td>-1.938184</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.706402</td>\n      <td>1.034314</td>\n      <td>-0.167254</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.737308</td>\n      <td>1.237786</td>\n      <td>-0.167254</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.883002</td>\n      <td>0.220428</td>\n      <td>1.603675</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.059603</td>\n      <td>1.237786</td>\n      <td>-0.167254</td>\n    </tr>\n    <tr>\n      <th>722</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1.324504</td>\n      <td>-1.000402</td>\n      <td>-1.938184</td>\n    </tr>\n    <tr>\n      <th>720</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.618102</td>\n      <td>-1.000402</td>\n      <td>-1.938184</td>\n    </tr>\n  </tbody>\n</table>\n<p>719 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[['num_words', 'longest_word_length', 'shortest_word_length']] = scaler.fit_transform(X_train[['num_words', 'longest_word_length', 'shortest_word_length']])\n",
    "X_test[['num_words', 'longest_word_length', 'shortest_word_length']] = scaler.transform(X_test[['num_words', 'longest_word_length', 'shortest_word_length']])\n",
    "\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bcc5ca20457e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimization\u001b[0m  \u001b[1;31m# to create AdamW optmizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_text'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optmizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and multilabel-indicator targets",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2ba37dbd46d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\QandU\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\QandU\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\QandU\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict\n",
    "\n",
    "acc = accuracy_score(y_test, y_predict_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}